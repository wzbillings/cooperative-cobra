{
  "hash": "314eb7b5e68a73977aeaa151fa1b3ab6",
  "result": {
    "markdown": "---\ntitle: \"Part 2: Linear Regression\"\ndate: last-modified\nauthor: Zane Billings\ntoc: true\nnumber-sections: true\n---\n\nOkay, I guess in this section we are going to implement gradient descent in\norder to build a linear regression model. In theory, I understand why\nthis is good from a pedagogical sense. We can use gradient descent for\nmuch more complicated models. But as a statistician, it makes me upset that\nthere are multiple people who learn this without exposure to stats 101 or\nthe theory of linear regression.\n\nAnyways. I'll stop whining and get started. Since this one involves some\ndata, I might do a little bit of mixing R and python -- not a lot, but I'm\ndefinitely not going to learn how to make a nice table in python right now\nwhen I could always save my python model results in a plain text file and\nload them into a Quarto doc to play nice with `gt` or whatever.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nimport numpy as np\n```\n:::\n\n\n# Training data\n\nContinuing in the great tradition of predictive modeling, we will have separate\ntraining data and testing data. I don't have a lot else to say about this\nbecause I'm really just trying to figure out pytorch here, I already\nknow a pretty good amount about predictive modeling, regression, and gradient\ndescent.\n\nFirst we have the input data set -- this is a matrix of predictors.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Input (temp, rainfall, humidity)\ninputs = np.array([[73, 67, 43], \n                   [91, 88, 64], \n                   [87, 134, 58], \n                   [102, 43, 37], \n                   [69, 96, 70]], dtype='float32')\n```\n:::\n\n\nNow we have the target data set -- the matrix of outcomes. One thing I do\nlike about this approach is that we can fit multiple independent outcomes at\nthe same time. In many popular regression packages, this is not the case.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Targets (apples, oranges)\ntargets = np.array([[56, 70], \n                    [81, 101], \n                    [119, 133], \n                    [22, 37], \n                    [103, 119]], dtype='float32')\n```\n:::\n\n\nI copied this code from the notes (you can tell because it isn't indented the\nsame way I like to indent my code), so the first thing we need to do is\nconvert to `torch` tensors.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ninputs = torch.from_numpy(inputs)\ntargets = torch.from_numpy(targets)\n```\n:::\n\n\n# Linear regression (via gradient descent) from scratch\n\nYou can tell we're doing machine learning because they call coefficients\n\"weights and biases\", which is insane to me because those both mean\nsomething completely different in the world of normal people. To clarify\nthis for myself in the future, the model we are going to fit is\n\\begin{align*}\n\\text{apples}_i &= w_{11} \\cdot \\text{temp} + w_{12} \\cdot \\text{rainfall} +\nw_{13} \\cdot \\text{humidity} + b_1 \\\\\n\\text{oranges}_i &= w_{21} \\cdot \\text{temp} + w_{22} \\cdot \\text{rainfall} +\nw_{23} \\cdot \\text{humidity} + b_2\n\\end{align*}\nwhich we can express in tensor language as\n$$\n\\begin{bmatrix} \\text{apples}_1 & \\text{oranges}_1 \\\\ \\vdots & \\vdots \\\\\n\\text{apples}_n & \\text{oranges}_n \\end{bmatrix} = \\begin{bmatrix} \\text{temp}_1\n& \\text{rainfall}_1 & \\text{humidity}_1 \\\\ \\vdots & \\vdots & \\vdots \\\\\n\\text{temp}_n & \\text{rainfall}_n & \\text{humidity}_n \\end{bmatrix}\n\\begin{bmatrix} w_{11} & w_{21} \\\\ w_{12} & w_{22} \\\\ w_{13} & w_{23}\n\\end{bmatrix} + \\begin{bmatrix} b_1 & b_2 \\\\ \\vdots & \\vdots \\\\ b_1 & b_2\n\\end{bmatrix},\n$$\nor more succinctly,\n$$\n\\left[ \\mathbf{y_1} \\ \\  \\mathbf{y_2} \\right] = X w^{T} + b.\n$$\n\nThe basic idea of gradient descent is that we'll define a loss function for our\nmodel, and use the gradient of that loss function to tell us what direction\nwe should move in. I.e., how should we adjust the weights and biases of our\nmodel in order to get a better fit.\n\n## Starting values\n\nWe'll start with randomly generated weights\nand biases. (Typically, if we were choosing starting values for a more\ncomplicated model, I would recommend using the linear regression solutions since\nit is easy and fast!)\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nw = torch.randn(2, 3, requires_grad = True)\nb = torch.randn(2, requires_grad = True)\nw; b\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\ntensor([2.4130, 0.3548], requires_grad=True)\n```\n:::\n:::\n\n\nApparently, `torch.randn` generates numbers to fill a tensor of the specified\ndimension from the standard normal distribution.\n\n## Initial fit\n\nNext we'll fit our model\nfor the first time. We'll do that by defining a function that fits the model,\nand then invoking it. Note that `@` means \"matrix multiplication\" in `torch`.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef model(x, w, b):\n\t\"\"\" Fits the linear regression model Y = X * w + b given tensors\n\t    X, w, and b of correct dimension.\"\"\"\n\treturn x @ w.t() + b\n\nfit = model(inputs, w, b)\nfit\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\ntensor([[69.1051, 18.5715],\n        [85.4509, 17.9268],\n        [91.3981, 76.7158],\n        [88.2252, -8.8150],\n        [68.9100, 25.7306]], grad_fn=<AddBackward0>)\n```\n:::\n:::\n\n\nHmm, I am guessing that's pretty bad `emoji::emoji(\"smile\")`.\nBut we need a way to determine just **how** bad\nthis fit is. This is the role of the **loss function.**\n\n## Loss function\n\nFor this, we'll use\nthe normal loss function for linear regression, which is called the **mean**\n**squared error**. To do this, we subtract the target matrix from the\npredictions, square these differences, and take the average of all the\nsquared differences. It's interesting to think about this working for two\nindependent linear models at the same time, but I think that it does work. I\nwon't prove it though, but it intuitively seems like the loss function will\nbe a paraboloid and therefore there's only one way to go to get to the\nsolution that minimizes the loss for both regressions.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ndef mse(truth, estimate):\n\t\"\"\" Computes the MSE, given a truth tensor and an estimate tensor.\"\"\"\n\tdiff = truth - estimate;\n\treturn torch.sum(diff * diff) / diff.numel()\n\nloss = mse(fit, targets)\nloss; loss ** 0.5\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\ntensor(54.7846, grad_fn=<PowBackward0>)\n```\n:::\n:::\n\n\nThe second number is the square root of the MSE, which is in the same units\nas the target matrix. Of course by interpreting it, we are comparing apples\nand oranges `r emoji::emoji(\"grin\")` but we can in some sense say that each\nprediction differs, on average, from the true response value by\n`python round((loss ** 0.5).item(), 2)` units. Note that if we centered and\nscaled all of our variables before modeling, we wouldn't have this potential\nweird unit conflict.\n\n## Adjusting parameter values\n\nNow that we have computed the loss function, we need the gradient in order\nto determine how we should update our weights and biases.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nloss.backward()\nw.grad\nb.grad\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```\ntensor([  4.4179, -65.9741])\n```\n:::\n:::\n\n\nNow we know what direction we should go, but we don't know **how much** we\nshould travel in that direction. This parameter is often called the\n*learning rate* of the model, or the *step size* for gradient descent. Typically\nwe want to take very small steps to ensure we don't miss the minimum (minima)\nof the loss function. For this, I'll use the same value that was used in the\ntutorial, `10^-5`.\n\nTechnical note: we use the `with torch.no_grad():` statement here to ensure\nthat only the `w` and `b` objects are updated here, we don't want this\nto get tracked with their gradients.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nwith torch.no_grad():\n\tw -= w.grad * 1e-5\n\tb -= b.grad * 1e-5\nw; b\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\ntensor([2.4130, 0.3554], requires_grad=True)\n```\n:::\n:::\n\n\nWe can do a quick check to ensure that the new loss is actually lower.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nprint(\"Old RMSE:\", loss ** 0.5)\nfit = model(inputs, w, b)\nloss = mse(targets, fit)\nprint(\"New RMSE:\", loss ** 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOld RMSE: tensor(54.7846, grad_fn=<PowBackward0>)\nNew RMSE: tensor(47.7372, grad_fn=<PowBackward0>)\n```\n:::\n:::\n\n\nOK, that's good. Next, we want to zero out the gradients, because apparently\n`torch` adds the gradients together at each step, which is weird to me but\nI guess it is important to how all this works underneath. I guess both this\nand the `no_grad()` step are necessary?\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nw.grad.zero_()\nb.grad.zero_()\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\ntensor([0., 0.])\n```\n:::\n:::\n\n\n## Training for multiple epochs\n\nNow, we could continue to do this manually over and over. But I don't really\nwant to do that, so let's write a loop. The tutorial just trains for a fixed\nnumber of epochs (iterations of the gradient descent algorithm, which are\nfor some reason called epochs instead of model fitting iterations), but instead\nof doing that I would prefer to iterate until the loss stops changing.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nloss_diff = 2\nold_loss = 1\nepochs_run = 0\nwhile abs(loss_diff) > 1e-2:\n\t# Save the old loss so we don't overwrite it\n\told_loss = loss\n\t\n\t# Fit the model and calculate the loss\n\tfit = model(inputs, w, b)\n\tloss = mse(targets, fit)\n\t\n\t# Update the parameters\n\tloss.backward()\n\twith torch.no_grad():\n\t\tw -= w.grad * 1e-5\n\t\tb -= b.grad * 1e-5\n\t\tw.grad.zero_()\n\t\tb.grad.zero_()\n\t\n\t# Calculate the difference in loss so we know if we are done\n\tloss_diff = old_loss - loss\n\tepochs_run += 1\n```\n:::\n\n\nAnd to think that the analytic solution only requires the model to be fit once!\n(And even if you use Fisher scoring, 50 is already an extremely high\nnumber of iterations…) Anyways, we can look at the final fit and loss.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nfit\nloss\nepochs_run\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\n1\n```\n:::\n:::\n\n\n# The Pytorch built-in linear neural net\n\nFortunately, if we want to fit a linear regression using `torch` (for whatever\nreason), we don't have to do this whole thing every time. There are actually\nbuilt-in functions that can implement this model for us.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nimport torch.nn as nn\n```\n:::\n\n\nWe'll use a slightly larger set of training data this time. Again, I just\ncopied this from the tutorial.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# Input (temp, rainfall, humidity)\ninputs = np.array([[73, 67, 43], \n                   [91, 88, 64], \n                   [87, 134, 58], \n                   [102, 43, 37], \n                   [69, 96, 70], \n                   [74, 66, 43], \n                   [91, 87, 65], \n                   [88, 134, 59], \n                   [101, 44, 37], \n                   [68, 96, 71], \n                   [73, 66, 44], \n                   [92, 87, 64], \n                   [87, 135, 57], \n                   [103, 43, 36], \n                   [68, 97, 70]], \n                  dtype='float32')\n\n# Targets (apples, oranges)\ntargets = np.array([[56, 70], \n                    [81, 101], \n                    [119, 133], \n                    [22, 37], \n                    [103, 119],\n                    [57, 69], \n                    [80, 102], \n                    [118, 132], \n                    [21, 38], \n                    [104, 118], \n                    [57, 69], \n                    [82, 100], \n                    [118, 134], \n                    [20, 38], \n                    [102, 120]], \n                   dtype='float32')\n\ninputs = torch.from_numpy(inputs)\ntargets = torch.from_numpy(targets)\n```\n:::\n\n\nInstead of manually referring to the inputs and targets separately, we'll\nuse a `TensorDataset`, which links these together and allows us to access\nthe correct targets and inputs together in a tuple. This seems a lot more\ncomplicated than having a table with column names as accessors (e.g. R's\n`data.frame`), but I assume there is a performance reason or something for\ndoing it like this.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nfrom torch.utils.data import TensorDataset\n\ntrain_ds = TensorDataset(inputs, targets)\ntrain_ds[0:3]\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n(tensor([[ 73.,  67.,  43.],\n         [ 91.,  88.,  64.],\n         [ 87., 134.,  58.]]),\n tensor([[ 56.,  70.],\n         [ 81., 101.],\n         [119., 133.]]))\n```\n:::\n:::\n\n\nSo we can see that what is printed here is a tuple of two tensors, with three\nrows each. The first tensor is the first three input rows, and the second\ntensor is the first three target rows. \n\nWe apparently also need to create a `DataLoader` to split the data into batches.\nThis apparently provides other utilities as well. I can see why this would\nbe helpful with a very large dataset. However, I think it would be more useful\nto stream data — if the entire dataset is large enough to cause problems, maybe\nit shouldn't be stored entirely in memory. The video tutorial mentioned this\nas well, but seemed to ignore the fact that the entire dataset is already\nloaded in memory.\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nfrom torch.utils.data import DataLoader\ntrain_dl = DataLoader(train_ds, 5, shuffle = True)\n```\n:::\n\n\nApparently the normal way to use this DataLoader is with a `for-in` construct,\nwhich I don't really like. I know they are often convenient to write, but\nI personally tend to prefer always using indices for my for loop. But I don't\nreally know how to do that with this object, so maybe this is one of those\nweird python things that I just have to live with.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nfor xb, yb in train_dl:\n\tprint('batch:')\n\tprint(xb)\n\tprint(yb)\n\tbreak # Just show the first batch of data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nbatch:\ntensor([[ 73.,  67.,  43.],\n        [ 69.,  96.,  70.],\n        [ 73.,  66.,  44.],\n        [ 87., 135.,  57.],\n        [ 91.,  88.,  64.]])\ntensor([[ 56.,  70.],\n        [103., 119.],\n        [ 57.,  69.],\n        [118., 134.],\n        [ 81., 101.]])\n```\n:::\n:::\n\n\nEspecially with having to use that \"break\" construct there has to be a better\nway to do this. But I won't worry about that for now. For now we need\nto talk about how a linear regression model can be represented as a neural\nnetwork.\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nmodel = nn.Linear(3, 2)\nprint(model.weight)\nprint(model.bias)\nlist(model.parameters())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nParameter containing:\ntensor([[ 0.4001,  0.2022,  0.0558],\n        [-0.1958,  0.0031, -0.0481]], requires_grad=True)\nParameter containing:\ntensor([ 0.2745, -0.0567], requires_grad=True)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n[Parameter containing:\n tensor([[ 0.4001,  0.2022,  0.0558],\n         [-0.1958,  0.0031, -0.0481]], requires_grad=True),\n Parameter containing:\n tensor([ 0.2745, -0.0567], requires_grad=True)]\n```\n:::\n:::\n\n\nThis creates a neural network with 3 inputs and 2 outputs that applies a linear\ntransformation (i.e. $y = Xw^{T} + b$) to the data. The weights and biases are\ninitialized with random values. Now we can call this model exactly the\nsame way as our handmade bespoke linear regression code.\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nfit = model(inputs)\nfit[0:3]\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\ntensor([[ 45.4227, -16.2053],\n        [ 58.0406, -20.6729],\n        [ 65.4047, -19.4572]], grad_fn=<SliceBackward0>)\n```\n:::\n:::\n\n\nPytorch also comes with built-in loss functions, stored in yet another\nseparate module that we must import.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nimport torch.nn.functional as F\nloss_fn = F.mse_loss\n\nloss = loss_fn(model(inputs), targets)\nloss\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\ntensor(7439.5747, grad_fn=<MseLossBackward0>)\n```\n:::\n:::\n\n\nNow we just have to implement an optimization routine. Apparently there are\nmultiple to choose from, but the tutorial recommends stochastic gradient\ndescent, which is one that I like a lot anyways. It's better in general\nthan deterministic gradient descent, but for linear regression both are\noverkill. We are very unlikely to have any advantage from SGD over regular\nGD for this problem.\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nopt = torch.optim.SGD(model.parameters(), lr = 1e-5)\n```\n:::\n\n\nNow, we just need to put it all together. Apparently we can do\n`opt.step()` to update the parameters without needing the `no_grad()` bit.\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ndef fit_model(num_epochs, model, loss_fn, opt, train_dl):\n\t\"\"\" This puts it all together.\"\"\"\n\t# Iterate for a pre-defined number of epochs\n\tfor epoch in range(num_epochs):\n\t\t# Get the next batch from the DataLoader\n\t\tfor xb, yb in train_dl:\n\t\t\t# Fit the model with current parameters\n\t\t\tpred = model(xb)\n\t\t\t# Calculate the loss\n\t\t\tloss = loss_fn(pred, yb)\n\t\t\t# Compute the gradients\n\t\t\tloss.backward()\n\t\t\t# Update the parameters\n\t\t\topt.step()\n\t\t\t# Reset the gradients\n\t\t\topt.zero_grad()\n\t\t\t\n\t\t# Print current progress every 10th epoch\n\t\tif (epoch+1) % 10 == 0:\n\t\t\tprint(\n\t\t\t\t'Epoch [{}/{}], Loss: {:.4f}'.format(\n\t\t\t\t\tepoch+1,\n\t\t\t\t\tnum_epochs,\n\t\t\t\t\tloss.item()\n\t\t\t\t)\n\t\t\t)\n```\n:::\n\n\nNow we can run the model. This time I decided to be lazy and just use\na fixed number of epochs like the tutorial said.\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\ntorch_fit = fit_model(100, model, loss_fn, opt, train_dl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch [10/100], Loss: 454.6852\nEpoch [20/100], Loss: 428.9344\nEpoch [30/100], Loss: 140.7702\nEpoch [40/100], Loss: 163.9316\nEpoch [50/100], Loss: 135.4273\nEpoch [60/100], Loss: 31.5637\nEpoch [70/100], Loss: 70.4598\nEpoch [80/100], Loss: 40.3923\nEpoch [90/100], Loss: 21.5594\nEpoch [100/100], Loss: 18.0169\n```\n:::\n:::\n\n\nBecause we are doing SGD, the loss doesn't have to go down at every step. We\ncan see that we actually got some lower values than the final one. But I guess\nwe are not going to talk about that in this part of the tutorial. The final\nstep is to get some predictions for new values.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nmodel(torch.tensor([[75., 63, 44]]))\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```\ntensor([[55.0307, 68.2699]], grad_fn=<AddmmBackward0>)\n```\n:::\n:::\n\n\nWell, that was pretty fun. But I do think we should figure out that part of\nthe model not optimizing to the best fit. We could change that in the loop,\nprobably (only call optim.step() if the new loss is lower, maybe). But anyways,\nthat's the end of this section of the tutorial.\n\n<!-- END OF FILE -->\n\n",
    "supporting": [
      "Module2-LinearRegression_files"
    ],
    "filters": [],
    "includes": {}
  }
}