{
  "hash": "ed8ba22d660a4bed1736d692d1917a1f",
  "result": {
    "markdown": "---\ntitle: \"Part 3: Logistic Regression and Working with Images\"\ndate: last-modified\nauthor: Zane Billings\ntoc: true\nnumber-sections: true\n---\n\nThis section will be about \"logistic\" regression (see why I don't like\nthe name later) as well as working with images in `torch` using the\nMNIST dataset. Working with the MNIST dataset is something I read a lot\nof examples about but nothing something. First we need to get the\ndataset.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport torch\nimport torchvision\n\n# Download the data\ntrain = torchvision.datasets.MNIST(root = \"static/\", download = True)\ntest = torchvision.datasets.MNIST(root = \"static/\", train = False)\n```\n:::\n\n\nNow since the dataset is composed of 28x28 images, we can plot one of\nthem to see what we are dealing with.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nex_plot = plt.imshow(train[0][0], cmap = 'gray')\nplt.show(ex_plot)\n```\n\n::: {.cell-output .cell-output-display}\n![](Module3-LogisticRegression_files/figure-html/cell-3-output-1.png){width=415 height=411}\n:::\n:::\n\n\nSo now that we have all these images (which we will load lazily, which I\nlearned is actually a nice property of a tensorflow dataset / data\nloader) we need to turn them into something we can use and model with\n`torch`. So first we have to convert the images into tensors. Apparently\nthe `torchvision.transforms` has specific functionality for doing this.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport torchvision.transforms\ntrain = torchvision.datasets.MNIST(\n\troot = \"static/\",\n\ttrain = True,\n\ttransform = torchvision.transforms.ToTensor()\n)\ntest = torchvision.datasets.MNIST(\n\troot = \"static/\",\n\ttrain = False,\n\ttransform = torchvision.transforms.ToTensor()\n)\n```\n:::\n\n\nI already know how a grayscale image is stored in the computer (thanks\nto when I had to do a bunch of microscopy stuff in undergrad) so I'll\nskip messing around with that. The resulting tensor will be 1x28x28\n(instead of just 28x28 for whatever reason, idk) where each of the\nvalues is the intensity of that pixel. Anyways now that we have actual\ntensors that we can use in `torch` models, we want to do a bit more\nhousekeeping.\n\n`R` guru Julia Silge calls this bit \"spending the data budget\" which I\nlike and I've taken to saying that also. We already have the standard\ntest set (used so that different researchers can directly compare their\nmodels on this canonical dataset) but we'll also want a validation set\nso we can do better at training out model. We'll take a set of the\ntraining data and use it as the validation set. We're allowed to test\nour models' performances on this dataset, unlike the test set which we\ncannot see until we have finished model-building if we want unbiased\nperformance metrics.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\ntrain_ds, val_ds = torch.utils.data.random_split(\n\ttrain, [50000, 10000]\n)\n```\n:::\n\n\nAnd since this dataset is so big and also filled with images, we'll want\nto create a data loader to handle batch loading the data. I think this\nis actually a good application of this, unlike last time. Note that I\npicked 128 as the batch size just cause the tutorial did. We want to\nshuffle the training data each time it is loaded because this can help\nin training the model, but since the validation data are only used for\nevaluation, not for model fitting, they do not need to be shuffled (it\ndoesn't matter if they are or not).\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfrom torch.utils.data import DataLoader\nbs = 128\ntrain_loader = DataLoader(train_ds, bs, shuffle = True)\nval_loader = DataLoader(test, bs)\n```\n:::\n\n\n# Doing \"logistic\" regression\n\nNow this is the one part of the tutorial that I take issue with. It\nkeeps calling this *logistic regression*. What we're actually doing here\nis called *softmax multinomial regression*. According to wikipedia, a\nlot of people also call it logistic regression and it's a common way to\nrefer to this model. But the machine learning people who call it that\nalso use stochastic gradient descent for regression, so. You know.\nAnyways, logistic regression gets its name from the logit link function,\nwhich we aren't using here. So I don't think it's appropriate to call\nthis model logistic regression. Technically we shouldn't even call it\nsoftmax regression, we should call it softargmax regression, because\nsoftmax is an approximation to the argmax function, not to the max\nfunction. So you know what? I'm going to call it *softargmax multinomial\nregression* and none of you can stop me. Let's call things what they\nactually are.\n\nAnyways.\n\nWe will, of course, begin by constructing a neural network with a neural\nnetwork with 10 target nodes (for the digits 0 to 9 in the data set).\nSince we're doing torch or whatever we have to do a neural net for\neverything. And since we're doing softargmax multinomial regression, we\nget 10 output classes instead of the standard 9 plus one reference\ngroup. Which is fine, I don't have a problem with that part. We've been\nthrough this before so I won't say too much more about it.\n\nThe first argument is the input space. We actually have 28 x 28 features\nper image, that's how many pixels we have and each one is a feature\nwe'll use for model fitting. Then we have the 10 classes that will be\nthe number of target nodes we have.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nimport torch.nn as nn\n\nmodel = nn.Linear(28 * 28, 10)\n```\n:::\n\n\nThis has *a lot* more parameters than any of the examples we've seen\nbefore, but it's actually the same thing. It's like if you had a little\nclock, it's basically the same as a big clock but just different sizes.\nIf you know how the little one works you pretty much know how the big\none works. (Clockmakers DO NOT call me out.)\n\nNow one thing we will have to deal with is the dimensions of our images.\nWe've just told our model that we have $28 \\times 28 = 784$ input\nvariables. So of course it will complain if we put in a $28 \\times 28$\ntensor instead of a $1 \\times 784$ vector tensor of inputs in the\ncorrect order, it just won't know what to do with all of them. And we\ngotta make sure everything stays in the right order or our model will\njust be absolutely donked.\n\nFor some ungodly reason, the tutorial wants me to define a new class\nhere. I'm sure there's going to be an example later on where this\nactually makes sense. But right now, defining a new class just to call\nthe `.reshape` method on the tensors is INSANE to me. Like using\ngradient descent for linear regression we are again trying to fill a\nthimble with a fire hose.\n\nI actually tried to do it a bunch of different ways but due to the way\neverything in python is an insane and there's no consistency to what's\nimmutable and what things get returned from functions, I'll just do it\nthis way. Even though it makes much more sense to any rational human to\njust reshape all of the data first. Especially if we're fitting all the\nmodels multiple times. That's just like, good programming (not repeating\ncode that doesn't need to be repeated). I think what I have below is not\nthe *best* way to do this, but it's the only way I could find that\ndidn't require me to load everything into memory at once, since I\ncouldn't figure out how to overwrite each item from a DataSet as it was\nloaded.\n\nI hate repeating this much code, but if I have to do it to avoid\nneedlessly repeating a transformation every time I call the model, I\nwill. I guess the age of code optimization is truly dead because\napparently (at least from my naive googling) there is no simple way to\napply a transformation to an entire DataSet after it is created. This\nentire `torch` ecosystem is insane to me, maybe I need to learn\n`tensorflow` also and see if it makes me want to smack my head into the\nwall the same amount or not.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\ntrain_val = torchvision.datasets.MNIST(\n\troot = \"static/\",\n\ttrain = True,\n\ttransform = torchvision.transforms.Compose([\n\t\ttorchvision.transforms.ToTensor(),\n\t\ttorchvision.transforms.Lambda(lambda x: x.reshape(-1, 784))\n\t\t])\n)\n\ntest = torchvision.datasets.MNIST(\n\troot = \"static/\",\n\ttrain = False,\n\ttransform = torchvision.transforms.Compose([\n\ttorchvision.transforms.ToTensor(),\n\ttorchvision.transforms.Lambda(lambda x: x.reshape(-1, 784))\n\t])\n)\n\ntrain_ds, val_ds = torch.utils.data.random_split(\n\ttrain_val, [50000, 10000]\n)\n\ntrain_loader = DataLoader(train_ds, bs, shuffle = True)\nval_loader = DataLoader(val_ds, bs)\n```\n:::\n\n\nBut I guess who cares if our code is good or optimized if we're doing\ndeep learning, right? Anyways now let's check that our model works.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfor img, lbl in train_loader:\n\tprint(img.shape)\n\tout = model(img.squeeze())\n\tprint(out)\n\tbreak\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntorch.Size([128, 1, 784])\ntensor([[ 0.2064,  0.0622, -0.1982,  ...,  0.0494, -0.2102, -0.1518],\n        [ 0.0579, -0.0297,  0.1772,  ..., -0.0649, -0.3285, -0.0511],\n        [ 0.1672,  0.0966,  0.0027,  ..., -0.0783, -0.1746, -0.1351],\n        ...,\n        [ 0.0534, -0.0795, -0.0459,  ...,  0.0106, -0.2020, -0.0723],\n        [ 0.0329,  0.0208,  0.1037,  ...,  0.0175, -0.0774, -0.1647],\n        [ 0.2122,  0.0861,  0.2479,  ...,  0.0037, -0.0769, -0.0358]],\n       grad_fn=<AddmmBackward0>)\n```\n:::\n:::\n\n\nYes, our model runs now, thank goodness. If it didn't I might call it\nquits and decided that this pytorch nonsense isn't for me. But now I\nshall persist, I suppose.\n\nNow we can fit the model. We'll use `softargmax` (aka the erroneously\nnamed softmax) as the \"activation function\". Since we only have one\nlayer in this neural net (since it is a linear model), this basically\nmeans we will take the inputs, put them in the linear model, then put\nthem through the softargmax function.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Rename it to the good name :)\ndef softargmax(input, dim = None, _stacklevel = 3, dtype = None):\n\treturn torch.nn.functional.softmax(input, dim, _stacklevel, dtype)\n\nsoftargmax(out.squeeze(), dim = 1)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\ntensor([[0.1231, 0.1066, 0.0821,  ..., 0.1052, 0.0811, 0.0860],\n        [0.0983, 0.0901, 0.1108,  ..., 0.0869, 0.0668, 0.0882],\n        [0.1168, 0.1088, 0.0990,  ..., 0.0913, 0.0830, 0.0863],\n        ...,\n        [0.1044, 0.0914, 0.0946,  ..., 0.1001, 0.0809, 0.0921],\n        [0.1004, 0.0992, 0.1078,  ..., 0.0989, 0.0900, 0.0824],\n        [0.1117, 0.0985, 0.1158,  ..., 0.0907, 0.0837, 0.0872]],\n       grad_fn=<SoftmaxBackward0>)\n```\n:::\n:::\n\n\n<!-- END OF FILE -->\n\n",
    "supporting": [
      "Module3-LogisticRegression_files"
    ],
    "filters": [],
    "includes": {}
  }
}